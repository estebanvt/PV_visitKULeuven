{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook illustrating aspects of disparity estimation\n",
    "\n",
    "First of all, we load the following libraries\n",
    "* cv2, the OpenCV library containing implementations of many image processing and computer vision algorithms,\n",
    "* math and numpy for some general math,\n",
    "* and finally matplotlib for displaying our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load a left and right image as input for our disparity estimation. We convert the images into grayscale to simplify some of the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_l = cv2.imread('data/view_left.png')\n",
    "img_r = cv2.imread('data/view_right.png')\n",
    "h,w,c = img_l.shape\n",
    "img_l= cv2.resize(img_l,(round(0.5*w), round(0.5*h)), interpolation = cv2.INTER_LINEAR)\n",
    "img_r= cv2.resize(img_r,(round(0.5*w), round(0.5*h)), interpolation = cv2.INTER_LINEAR)\n",
    "I_gray_l = cv2.cvtColor(img_l, cv2.COLOR_BGR2GRAY)\n",
    "I_gray_r = cv2.cvtColor(img_r, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(16, 12), sharex=True, sharey=True)\n",
    "ax1.imshow(I_gray_l,'gray')\n",
    "ax2.imshow(I_gray_r,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A border is added to the right of the image to avoid problems in the further calculations with indices that would run outside of the image borders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmin = 0\n",
    "dmax = 120\n",
    "img_l_pad = np.float32(cv2.copyMakeBorder(I_gray_l,0, 0, -dmin, dmax, cv2.BORDER_REPLICATE,0))\n",
    "img_r_pad = np.float32(cv2.copyMakeBorder(I_gray_r,0, 0, -dmin, dmax, cv2.BORDER_REPLICATE,0))\n",
    "h,w = I_gray_l.shape\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(16, 12), sharex=True, sharey=True)\n",
    "ax1.imshow(img_l_pad,'gray')\n",
    "ax2.imshow(img_r_pad,'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost volume calculation\n",
    "We calculate the cost volume using the absolute grayscale image difference between left and right image as cost measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_volume = np.zeros([h,w,dmax-dmin])\n",
    "for i in range(dmin,dmax):\n",
    "    cost_volume[:,:,i-dmin] = abs(img_l_pad[:,i-dmin:i-dmin+w] - img_r_pad[:,-dmin:-dmin+w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display slices of the cost volume at different disparity levels, showing the error image for various disparity levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(16, 6), sharex=True, sharey=True)\n",
    "ax1.imshow(cost_volume[:,:,0], 'gray')\n",
    "ax2.imshow(cost_volume[:,:,72], 'gray')\n",
    "ax3.imshow(cost_volume[:,:,100], 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now plot row 300 from the left (blue) and right (orange) image, and try to find the best match at pixel (300,186). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 300\n",
    "c = 186\n",
    "d = 0\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(8, 4))\n",
    "ax1.plot(img_l_pad[r,d-dmin:d-dmin+w])\n",
    "ax1.plot(img_r_pad[r,-dmin:-dmin+w])\n",
    "ax1.axvline(x=c, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first attempt, we examine the cost volume at location (300,186). The minimum value can be found at disparity 50, so we shift the left image by 50 pixels and plot this together with the original right image line.\n",
    "\n",
    "Note how the error is 0 at this location for disparity 50, but the plots don't seem to match well yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(cost_volume[r,c,:])\n",
    "print(\"optimum in the cost volume is found at \", min_loc, \" with a cost of \", min_val)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "ax1.plot(range(dmin,dmax),cost_volume[r,c,:])\n",
    "d=min_loc[1]\n",
    "ax2.plot(img_l_pad[r,d-dmin:d-dmin+w])\n",
    "ax2.plot(img_r_pad[r,-dmin:-dmin+w])\n",
    "ax2.axvline(x=c, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply this to the entire cost volume, and select at each pixel location the disparity with the lowest cost, we get the following disparity image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = np.argmin(cost_volume, axis=2)\n",
    "plt.imshow(depth, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the result is very noisy. Therefore, let us evaluate the cost also at neighboring pixels when building the cost volume. In this way, we aggregate the matching cost of neighboring pixels into the cost volume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_volume2 = np.zeros([h,w,dmax-dmin])\n",
    "win = 3\n",
    "for i in range(dmin,dmax):\n",
    "    for j in range(-win,win):\n",
    "        for k in range(-win,win):\n",
    "            cost_volume2[win:-win,win:-win,i-dmin] += abs(img_l_pad[win+j:-win+j,i-dmin+win+k:i-dmin+w-win+k] - img_r_pad[win+j:-win+j,-dmin+win+k:-dmin+w-win+k])\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(cost_volume2[r,c,:])\n",
    "print(\"optimum in the cost volume is found at \", min_loc, \" with a cost of \", min_val)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "ax1.plot(range(dmin,dmax),cost_volume2[r,c,:])\n",
    "d=min_loc[1]\n",
    "ax2.plot(img_l_pad[r,d-dmin:d-dmin+w])\n",
    "ax2.plot(img_r_pad[r,-dmin:-dmin+w])\n",
    "ax2.axvline(x=c, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, this can be done by filtering the original cost volume. The result is already much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 5\n",
    "kernel = np.ones((kernel_size,kernel_size),np.float32)/(kernel_size*kernel_size)\n",
    "costvolume_filt = cv2.filter2D(cost_volume,-1,kernel)\n",
    "\n",
    "depth = np.argmin(costvolume_filt, axis=2)\n",
    "\n",
    "plt.imshow(depth, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparity estimation in OpenCV\n",
    "OpenCV already includes implementations of a few disparity estimation algorithms, which are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgL = cv2.imread('data/view_left.png',0)\n",
    "imgR = cv2.imread('data/view_right.png',0)\n",
    "\n",
    "stereo = cv2.StereoBM_create(numDisparities=256, blockSize=15)\n",
    "disparity = stereo.compute(imgL,imgR)\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the code below shows another disparity estimation algorithm. \n",
    "It also projects the image pixels back into 3D space using the estimated disparities. This result is stored in the file out.ply, and can be visualized using a tool like the open source Meshlab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simple example of stereo image matching and point cloud generation.\n",
    "Resulting .ply file cam be easily viewed using MeshLab ( http://meshlab.sourceforge.net/ )\n",
    "'''\n",
    "\n",
    "ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "'''\n",
    "\n",
    "def write_ply(fn, verts, colors):\n",
    "    verts = verts.reshape(-1, 3)\n",
    "    colors = colors.reshape(-1, 3)\n",
    "    verts = np.hstack([verts, colors])\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "        np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('loading images...')\n",
    "    imgL = cv2.pyrDown( cv2.imread('./data/view_left.png') )  # downscale images for faster processing\n",
    "    imgR = cv2.pyrDown( cv2.imread('./data/view_right.png') )\n",
    "\n",
    "    # disparity range is tuned for 'aloe' image pair\n",
    "    window_size = 3\n",
    "    min_disp = 16\n",
    "    num_disp = 112-min_disp\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "        numDisparities = num_disp,\n",
    "        blockSize = 16,\n",
    "        P1 = 8*3*window_size**2,\n",
    "        P2 = 32*3*window_size**2,\n",
    "        disp12MaxDiff = 1,\n",
    "        uniquenessRatio = 10,\n",
    "        speckleWindowSize = 100,\n",
    "        speckleRange = 32\n",
    "    )\n",
    "\n",
    "    print('computing disparity...')\n",
    "    disp = stereo.compute(imgL, imgR).astype(np.float32) / 16.0\n",
    "\n",
    "    print('generating 3d point cloud...',)\n",
    "    h, w = imgL.shape[:2]\n",
    "    f = 0.8*w                          # guess for focal length\n",
    "    Q = np.float32([[1, 0, 0, -0.5*w],\n",
    "                    [0,-1, 0,  0.5*h], # turn points 180 deg around x-axis,\n",
    "                    [0, 0, 0,     -f], # so that y-axis looks up\n",
    "                    [0, 0, 1,      0]])\n",
    "    points = cv2.reprojectImageTo3D(disp, Q)\n",
    "    colors = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)\n",
    "    mask = disp > disp.min()\n",
    "    out_points = points[mask]\n",
    "    out_colors = colors[mask]\n",
    "    out_fn = 'out.ply'\n",
    "    write_ply('out.ply', out_points, out_colors)\n",
    "    print('%s saved' % 'out.ply')\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 8))\n",
    "    ax1.imshow(cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB))\n",
    "    ax2.imshow((disp-min_disp)/num_disp,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
