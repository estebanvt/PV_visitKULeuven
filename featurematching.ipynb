{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature detection and matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(cv2.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature detection\n",
    "## Harris feature detector\n",
    "#### Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data'\n",
    "img1_building = cv2.imread(os.path.join(dataset_path, 'montmartre1.jpg'))\n",
    "height,width,channels = img1_building.shape\n",
    "img1_building = cv2.resize(img1_building,(round(0.25*width), round(0.25*height)), interpolation = cv2.INTER_LINEAR)\n",
    "img1_building = cv2.cvtColor(img1_building, cv2.COLOR_BGR2RGB)  # Convert from cv's BRG default color order to RGB\n",
    "img2_building = cv2.imread(os.path.join(dataset_path, 'montmartre2.jpg'))\n",
    "height,width,channels = img2_building.shape\n",
    "img2_building = cv2.resize(img2_building,(round(0.25*width), round(0.25*height)), interpolation = cv2.INTER_LINEAR)\n",
    "img2_building = cv2.cvtColor(img2_building, cv2.COLOR_BGR2RGB)  # Convert from cv's BRG default color order to RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Harris features and show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = np.float32(cv2.cvtColor(img1_building, cv2.COLOR_RGB2GRAY))\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "gray[dst>0.01*dst.max()]=255 #[0,0,255]\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "plt.imshow(gray,cmap=\"gray\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT features\n",
    "#### Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data'\n",
    "img1_building = cv2.imread(os.path.join(dataset_path, 'montmartre1.jpg'))\n",
    "height,width,channels = img1_building.shape\n",
    "img1_building = cv2.resize(img1_building,(round(0.25*width), round(0.25*height)), interpolation = cv2.INTER_LINEAR)\n",
    "img1_building = cv2.cvtColor(img1_building, cv2.COLOR_BGR2RGB)  # Convert from cv's BRG default color order to RGB\n",
    "img2_building = cv2.imread(os.path.join(dataset_path, 'montmartre2.jpg'))\n",
    "height,width,channels = img2_building.shape\n",
    "img2_building = cv2.resize(img2_building,(round(0.25*width), round(0.25*height)), interpolation = cv2.INTER_LINEAR)\n",
    "img2_building = cv2.cvtColor(img2_building, cv2.COLOR_BGR2RGB)  # Convert from cv's BRG default color order to RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate SIFT features and show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp1_sift, des1_sift = sift.detectAndCompute(img1_building, None)\n",
    "img1_kp_sift = cv2.drawKeypoints(img1_building, kp1_sift, img1_building)\n",
    "kp2_sift, des2_sift = sift.detectAndCompute(img2_building, None)\n",
    "img2_kp_sift = cv2.drawKeypoints(img2_building, kp2_sift, img2_building)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.title('SIFT Interest Points')\n",
    "plt.imshow(img1_kp_sift); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORB features\n",
    "#### Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data'\n",
    "img1_building = cv2.imread(os.path.join(dataset_path, 'montmartre1.jpg'))\n",
    "height,width,channels = img1_building.shape\n",
    "img1_building = cv2.resize(img1_building,(round(0.25*width), round(0.25*height)), interpolation = cv2.INTER_LINEAR)\n",
    "img1_building = cv2.cvtColor(img1_building, cv2.COLOR_BGR2RGB)  # Convert from cv's BRG default color order to RGB\n",
    "img2_building = cv2.imread(os.path.join(dataset_path, 'montmartre2.jpg'))\n",
    "height,width,channels = img2_building.shape\n",
    "img2_building = cv2.resize(img2_building,(round(0.25*width), round(0.25*height)), interpolation = cv2.INTER_LINEAR)\n",
    "img2_building = cv2.cvtColor(img2_building, cv2.COLOR_BGR2RGB)  # Convert from cv's BRG default color order to RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate ORB features and show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()  # OpenCV 3 backward incompatibility: Do not create a detector with `cv2.ORB()`.\n",
    "kp1_orb, des1_orb = orb.detectAndCompute(img1_building, None)\n",
    "kp2_orb, des2_orb = orb.detectAndCompute(img2_building, None)\n",
    "img1_kp_orb = cv2.drawKeypoints(img1_building, kp1_orb, img1_building) # Draw circles.\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.title('ORB Interest Points')\n",
    "plt.imshow(img1_kp_orb); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brute force matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFMatcher with default parameters on SIFT features\n",
    "bf = cv2.BFMatcher()\n",
    "matches_bf = bf.knnMatch(des1_sift,des2_sift, k=2) # selecting k=2 best matches\n",
    "\n",
    "# Apply ratio test to best and second best match\n",
    "good_sift_bf = []\n",
    "for m,n in matches_bf:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good_sift_bf.append(m)\n",
    "\n",
    "img3 = cv2.drawMatches(img1_building,kp1_sift,img2_building,kp2_sift,good_sift_bf,img1_building,flags=2)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLANN-based matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "matches_flann = flann.knnMatch(des1_sift, des2_sift, k=2)\n",
    "\n",
    "# Apply ratio test to best and second best match\n",
    "matchesMask = [[0, 0] for i in range(len(matches_flann))]\n",
    "good_sift_flann = []\n",
    "for i, (m, n) in enumerate(matches_flann):\n",
    "    if m.distance < 0.55*n.distance:\n",
    "        matchesMask[i] = [1, 0]\n",
    "        good_sift_flann.append(m)\n",
    "\n",
    "draw_params = dict(matchColor=(0, 255, 0),\n",
    "                   singlePointColor=(255, 0, 0),\n",
    "                   matchesMask=matchesMask,\n",
    "                   flags=0)\n",
    "\n",
    "img3 = cv2.drawMatchesKnn(img1_building, kp1_sift, img2_building, kp2_sift, matches_flann, None, **draw_params)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img3); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brute force matcher on ORB features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches_orb = bf.match(des1_orb, des2_orb)\n",
    "matches_orb = sorted(matches_orb, key = lambda x: x.distance) # Sort matches by distance.  Best come first.\n",
    "    \n",
    "nmatches = 10\n",
    "img_matches = cv2.drawMatches(img1_building, kp1_orb, img2_building, kp2_orb, \n",
    "                              matches_orb[:nmatches], img2_building, flags=2) # Show top 10 matches\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.title('Brute force matcher on ORB features')\n",
    "plt.imshow(img_matches); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting (homography) using matched features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "if len(good_sift_flann)>MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1_sift[m.queryIdx].pt for m in good_sift_flann ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2_sift[m.trainIdx].pt for m in good_sift_flann ]).reshape(-1,1,2)\n",
    "\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "    #M, mask = cv2.findHomography(src_pts, dst_pts, 0,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "\n",
    "    h,w,d = img1_building.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "    img2 = cv2.polylines(img2_building,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "else:\n",
    "    print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "    matchesMask = None\n",
    "\n",
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "\n",
    "img3 = cv2.drawMatches(img1_building,kp1_sift,img2_building,kp2_sift,good_sift_flann,None,**draw_params)\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
